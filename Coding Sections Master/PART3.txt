# What is RESUME Tab
with tab2:
    st.title("ðŸ§  RESUME: Risk Evaluation and Suicide Understanding Monitoring Engine")
    
    # Overview Section
    st.header("ðŸ“‹ Project Overview")
    st.markdown("""
    RESUME is an advanced predictive analytics tool designed to identify and assess suicide risk among healthcare workers. 
    The project combines multiple analytical approaches to provide comprehensive risk assessment and monitoring.
    
    ðŸ”— **Project Website:** [RESUME Project Portal](https://www.resumeuk.org)
    
    ### ðŸŽ¯ Core Objectives
    1. Early Risk Detection
    2. Continuous Monitoring
    3. Predictive Analytics
    4. Evidence-Based Intervention Support
    
    ### â­ Key Features
    - ðŸ”„ Real-time risk assessment
    - ðŸ“Š Multi-modal data analysis
    - â±ï¸ Temporal pattern recognition
    - ðŸ“ˆ Interactive visualization
    - ðŸ”’ Secure data management
    """)

    # Technical Architecture
    st.header("ðŸ—ï¸ Technical Architecture")
    st.markdown("""
    ### ðŸ“¥ Data Collection
    - ðŸ“ Structured clinical assessments
    - ðŸ“Š Psychometric measurements
    - â±ï¸ Temporal behavioral patterns
    - ðŸŒ Environmental factors
    
    ### ðŸ”„ Analysis Pipeline
    1. ðŸ” Data Preprocessing
    2. âš™ï¸ Feature Engineering
    3. âš–ï¸ Risk Assessment
    4. ðŸ¤– Predictive Modeling
    5. ðŸ“Š Visualization
    """)

    st.header("ðŸ”® Predictive Models")
    st.markdown("""
    ### 1. ðŸ“ˆ Survival Analysis
    #### ðŸ“Š Kaplan-Meier Estimator
    - Estimates probability of remaining crisis-free over time
    - Non-parametric approach for time-to-event analysis
    - Accounts for censored data
    
    #### ðŸ“‰ Cox Proportional Hazards
    - Analyzes impact of multiple variables on survival
    - Hazard ratios quantify risk factors
    - Time-dependent covariate analysis
    
    ### 2. ðŸ¤– Machine Learning Models
    #### ðŸŒ³ XGBoost Classification
    - Gradient boosting framework
    - Features:
        - ðŸ‘¤ Demographic factors
        - ðŸ¥ Clinical indicators
        - ðŸ§  Psychosocial variables
        - ðŸŒ Environmental factors
    - Hyperparameter optimization
    - Cross-validation methodology
    
    ### 3. âš–ï¸ Risk Scoring System
    - Weighted combination of:
        - ðŸ“‹ Clinical assessments
        - ðŸ“š Historical data
        - ðŸ”„ Real-time indicators
        - ðŸŒ Environmental factors
    """)

    st.header("ðŸ“ Methodology")
    st.markdown("""
    ### ðŸ”„ Data Processing Pipeline
    1. **ðŸ“¥ Data Collection**
       - ðŸ“ Standardized assessments
       - ðŸ‘¨â€âš•ï¸ Clinical observations
       - â±ï¸ Temporal tracking
    
    2. **âš™ï¸ Feature Engineering**
       - ðŸ“Š Temporal aggregation
       - ðŸŽ¯ Risk factor computation
       - ðŸ”„ Interaction terms
    
    3. **ðŸ¤– Model Training**
       - âœ”ï¸ Cross-validation
       - âš™ï¸ Hyperparameter optimization
       - ðŸ”„ Model ensemble
    
    4. **ðŸŽ¯ Validation**
       - ðŸ‘¨â€âš•ï¸ Clinical validation
       - ðŸ“Š Statistical testing
       - ðŸ“ˆ Performance metrics
    """)

# Database Front Tab with Search and Filtering
with tab3:
    st.title("ðŸ“Š Database Overview")

    if not df.empty:
        st.header("ðŸ” Search and Filter")
        
        # Search functionality
        search_col1, search_col2 = st.columns([3, 1])
        with search_col1:
            search_term = st.text_input("Search across all fields:", "")
        with search_col2:
            search_button = st.button("Search")
        
        # Advanced filtering options
        with st.expander("Advanced Filters"):
            filter_col1, filter_col2, filter_col3 = st.columns(3)
            
            with filter_col1:
                # Demographic filters
                st.subheader("Demographics")
                age_range = st.slider("Age Range", 
                                     int(df['Age'].min()), 
                                     int(df['Age'].max()), 
                                     (int(df['Age'].min()), int(df['Age'].max())))
                
                selected_genders = st.multiselect("Gender", 
                                                 df['Sex'].unique().tolist(),
                                                 default=df['Sex'].unique().tolist())
            
            with filter_col2:
                # Occupational filters
                st.subheader("Occupation")
                selected_roles = st.multiselect("Healthcare Role", 
                                              df['Healthcare_Role'].unique().tolist(),
                                              default=df['Healthcare_Role'].unique().tolist())
                
                selected_departments = st.multiselect("Department", 
                                                    df['Department'].unique().tolist(),
                                                    default=df['Department'].unique().tolist())
            
            with filter_col3:
                # Risk filters
                st.subheader("Risk Factors")
                risk_level = st.slider("Suicidal Distress Level", 
                                      0, 10, (0, 10))
                
                crisis_filter = st.multiselect("Crisis Events", 
                                             [0, 1],
                                             default=[0, 1],
                                             format_func=lambda x: "Yes" if x == 1 else "No")
        
        # Apply filters
        filtered_df = df.copy()
        
        # Text search across all string columns
        if search_term:
            mask = pd.Series(False, index=filtered_df.index)
            for col in filtered_df.select_dtypes(include=['object']).columns:
                mask = mask | filtered_df[col].astype(str).str.contains(search_term, case=False, na=False)
            filtered_df = filtered_df[mask]
        
        # Apply demographic filters
        filtered_df = filtered_df[
            (filtered_df['Age'] >= age_range[0]) & 
            (filtered_df['Age'] <= age_range[1]) &
            (filtered_df['Sex'].isin(selected_genders))
        ]
        
        # Apply occupational filters
        filtered_df = filtered_df[
            (filtered_df['Healthcare_Role'].isin(selected_roles)) &
            (filtered_df['Department'].isin(selected_departments))
        ]
        
        # Apply risk filters
        filtered_df = filtered_df[
            (filtered_df['Suicidal_Distress'] >= risk_level[0]) &
            (filtered_df['Suicidal_Distress'] <= risk_level[1]) &
            (filtered_df['Crisis_Event'].isin(crisis_filter))
        ]
        
        # Display filter summary
        st.markdown(f"**Showing {len(filtered_df)} of {len(df)} records**")
        
        # Column selection
        st.subheader("ðŸ“‹ Select Columns to Display")
        all_columns = df.columns.tolist()
        default_columns = ["Observation_Date", "Age", "Sex", "Employment_Status",
                          "Healthcare_Role", "Department", "Suicidal_Distress", 
                          "Time_To_Crisis", "Crisis_Event"]
        selected_columns = st.multiselect("Choose columns:", all_columns, default=default_columns)
        
        # Display filtered data
        if selected_columns:
            st.dataframe(filtered_df[selected_columns].sort_values("Observation_Date", ascending=False))
        else:
            st.warning("Please select at least one column to display")
        
        if "Observation_Date" in filtered_df.columns:
            filtered_df = filtered_df.sort_values("Observation_Date", ascending=False)
        
        # Export options
        st.subheader("ðŸ“¤ Export Filtered Data")
        export_format = st.radio("Export Format:", ["CSV", "Excel", "JSON"], horizontal=True)
        
        if st.button("Export Data"):
            if export_format == "CSV":
                csv = filtered_df[selected_columns].to_csv(index=False)
                st.download_button(
                    label="Download CSV",
                    data=csv,
                    file_name="resume_filtered_data.csv",
                    mime="text/csv"
                )
            elif export_format == "Excel":
                # For Excel, we need to use a BytesIO object
                buffer = io.BytesIO()
                with pd.ExcelWriter(buffer, engine='xlsxwriter') as writer:
                    filtered_df[selected_columns].to_excel(writer, index=False)
                st.download_button(
                    label="Download Excel",
                    data=buffer.getvalue(),
                    file_name="resume_filtered_data.xlsx",
                    mime="application/vnd.ms-excel"
                )
            else:  # JSON
                json_data = filtered_df[selected_columns].to_json(orient="records")
                st.download_button(
                    label="Download JSON",
                    data=json_data,
                    file_name="resume_filtered_data.json",
                    mime="application/json"
                )
        
        
        # Data visualization options
        st.subheader("ðŸ“Š Quick Visualization")
        viz_col1, viz_col2 = st.columns(2)
        
        with viz_col1:
            chart_type = st.selectbox("Chart Type", ["Bar Chart", "Pie Chart", "Histogram", "Box Plot"])
        
        with viz_col2:
            if chart_type in ["Bar Chart", "Pie Chart"]:
                category_col = st.selectbox("Category Column", 
                                           [col for col in selected_columns if col in df.select_dtypes(include=['object']).columns])
            elif chart_type == "Histogram":
                numeric_col = st.selectbox("Numeric Column", 
                                         [col for col in selected_columns if col in df.select_dtypes(include=['number']).columns])
            else:  # Box Plot
                numeric_col = st.selectbox("Numeric Column", 
                                         [col for col in selected_columns if col in df.select_dtypes(include=['number']).columns])
                category_col = st.selectbox("Group By", 
                                          [col for col in selected_columns if col in df.select_dtypes(include=['object']).columns])
        
        # Generate visualization
        if chart_type == "Bar Chart" and 'category_col' in locals():
            fig = px.bar(filtered_df, x=category_col, title=f"Count by {category_col}")
            st.plotly_chart(fig)
        elif chart_type == "Pie Chart" and 'category_col' in locals():
            fig = px.pie(filtered_df, names=category_col, title=f"Distribution by {category_col}")
            st.plotly_chart(fig)
        elif chart_type == "Histogram" and 'numeric_col' in locals():
            fig = px.histogram(filtered_df, x=numeric_col, title=f"Distribution of {numeric_col}")
            st.plotly_chart(fig)
        elif chart_type == "Box Plot" and 'numeric_col' in locals() and 'category_col' in locals():
            fig = px.box(filtered_df, x=category_col, y=numeric_col, title=f"{numeric_col} by {category_col}")
            st.plotly_chart(fig)
    else:
        st.info("No data available. Please add entries using the Data Entry tab.")

    if not df.empty:
        # Public view of the database
        st.header("ðŸ“‹ Current Database Records")
        public_cols = [
            "Observation_Date", "Age", "Sex", "Employment_Status",
            "MH_Disorders", "Suicidal_Distress", "Time_To_Crisis",
            "Crisis_Event"
        ]
        st.dataframe(df[public_cols].sort_values("Observation_Date", ascending=False))
        
        # Basic statistics
        st.header("ðŸ“Š Quick Statistics")
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Total Records", len(df))
            st.markdown("*Total entries in database*")
        with col2:
            st.metric("Average Age", f"{df['Age'].mean():.1f}")
            st.markdown("*Mean age of healthcare workers*")
        with col3:
            st.metric("Crisis Events", int(df['Crisis_Event'].sum()))
            st.markdown("*Total recorded crisis incidents*")

        # Data Quality Metrics
        st.header("ðŸ” Data Quality Overview")
        missing_data = df[public_cols].isnull().sum()
        if missing_data.any():
            st.warning("Some records have missing data:")
            st.write(missing_data[missing_data > 0])
        else:
            st.success("All selected fields contain complete data")

        # Recent Updates
        st.header("ðŸ•’ Recent Updates")
        recent = df.sort_values("Observation_Date", ascending=False).head(5)
        st.markdown("Last 5 entries added to the database:")
        st.dataframe(recent[public_cols])

    else:
        st.info("No data available. Please add entries using the Data Entry tab.")
        st.markdown("""
        ### Getting Started
        1. Navigate to the Data Entry tab
        2. Add individual records or upload a CSV file
        3. Return here to view the database overview
        """)
